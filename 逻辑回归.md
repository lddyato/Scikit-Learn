逻辑回归是一个分类算法，它可以处理二元分类以及多元分类。
虽然它名字里面有“回归”两个字，却不是一个回归算法。
那为什么有“回归”这个误导性的词呢？个人认为，虽然逻辑回归是分类模型，但是它的原理里面却残留着回归模型的影子，
本文对逻辑回归原理做一个总结。

1. # 从线性回归到逻辑回归
我们知道，线性回归的模型是求出输出特征向量$Y$和输入样本矩阵$X$之间的线性关系系数$θ$，满足$Y=Xθ$。
此时我们的$Y$是连续的，所以是回归模型。如果我们想要$Y$是离散的话，怎么办呢？一个可以想到的办法是，我们对于这个$Y$再做一次函数转换，变为$g(Y)$。
如果我们令$g(Y)$的值在某个实数区间的时候是类别A，在另一个实数区间的时候是类别B，以此类推，就得到了一个分类模型。
如果结果的类别只有两种，那么就是一个二元分类模型了。逻辑回归的出发点就是从这来的。下面我们开始引入二元逻辑回归。

# 二元逻辑回归的模型
上一节我们提到对线性回归的结果做一个在函数g上的转换，可以变化为逻辑回归。
这个函数g在逻辑回归中我们一般取为sigmoid函数，形式如下：\(g(z) = \frac{1}{1+e^{-z}}\)&nbsp;

它有一个非常好的性质，即当z趋于正无穷时，\(g(z)\)趋于1，而当z趋于负无穷时，\(g(z)\)趋于0，这非常适合于我们的分类概率模型。另外，它还有一个很好的导数性质：\(g^{'}(z) = g(z)(1-g(z))\)&nbsp;这个通过函数对\(g(z)\)求导很容易得到，后面我们会用到这个式子。
如果我们令\(g(z)\)中的z为：\({z = x\theta}\)，这样就得到了二元逻辑回归模型的一般形式：\(h_{\theta}(x) = \frac{1}{1+e^{-x\theta}}\)&nbsp;


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
